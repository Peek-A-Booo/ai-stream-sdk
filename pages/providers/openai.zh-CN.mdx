import { Callout } from 'nextra/components'

import { OptionTable } from '@components/table'

# OpenAIStream

<Callout emoji="ğŸ’¡">
  æ‰€æœ‰ demo éƒ½æ˜¯åœ¨ **Next.js** ä¸­æ¼”ç¤ºçš„ï¼Œä¹Ÿå¯ä»¥æ‹“å±•åˆ°å…¶ä»–åœ°æ–¹å’Œæ¡†æ¶ä¸­ä½¿ç”¨ã€‚
</Callout>

åªè¦æ˜¯ç¬¦åˆ OpenAI å“åº”æ•°æ®æ ¼å¼çš„ API éƒ½å¯ä»¥ä½¿ç”¨ã€‚

## æŒ‡å¼•

### åˆ›å»ºè·¯ç”±

æˆ‘ä»¬æ¥åˆ›å»ºä¸€ä¸ª Next.js çš„è·¯ç”±å¤„ç†ç¨‹åº `app/api/chat/route.ts`ï¼Œä½¿ç”¨ Edge Runtimeï¼Œå€ŸåŠ© OpenAI æˆ–è‡ªå·±ä½¿ç”¨ fetch æ¥å®Œæˆå¯¹ OpenAI æµå¼æ•°æ®çš„å¤„ç†å¹¶è¿”å›å“åº”ã€‚

<Callout emoji="âš ï¸">éœ€è¦å°† **runtime** è®¾ç½®ä¸º **"edge"**</Callout>

```ts filename="app/api/chat/route.ts" copy
import { OpenAIStream } from 'ai-stream-sdk'
import OpenAI from 'openai'

const openai = new OpenAI({
  apiKey: 'sk-*****',
})

// æ³¨æ„! è¯·å°† runtime è®¾ç½®ä¸º 'edge'
export const runtime = 'edge'

export async function POST(request: Request) {
  const { messages } = await request.json()

  const response = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages,
    stream: true,
  })

  // æ‚¨è¿˜å¯ä»¥ä½¿ç”¨ fetch ç›´æ¥è®¿é—® OpenAI Endpoint
  // const response = await fetch('https://api.openai.com/v1/chat/completions', {
  //   headers: {
  //     'Content-Type': 'application/json',
  //     Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
  //   },
  //   method: 'POST',
  //   body: JSON.stringify({
  //     stream: true,
  //     model: 'gpt-3.5-turbo',
  //     messages,
  //   }),
  // })

  const stream = OpenAIStream(response)

  return new Response(stream)
}
```

### å“åº”ç»“æŸåå¤„ç†

å¯ä»¥é€šè¿‡å›è°ƒäº‹ä»¶æ¥è¿›è¡Œæ›´å¤šçš„å¤„ç†ã€‚ä¾‹å¦‚åœ¨å°†å®Œæˆæµå¼å“åº”å›ä¼ ç»™ç”¨æˆ·åï¼Œå¸Œæœ›è®¡ç®—å½“å‰æ¶ˆè€—çš„ Token æ•°é‡ï¼Œå¯ä½¿ç”¨ `onCompletion` å›è°ƒã€‚

```ts filename="app/api/chat/route.ts" copy
import { GPTTokens } from 'gpt-tokens'

export async function POST(request: Request) {
  const { messages } = await request.json()

  // ...

  const stream = OpenAIStream(response, {
    onStart: () => {
      // æµå¼å“åº”å¼€å§‹æ—¶å¯ä»¥åšä¸€äº›å¤„ç†
      console.log('æµå¼å“åº”å¼€å§‹')
    },
    onCompletion: (completion) => {
      console.log('æµå¼å“åº”ç»“æŸ', completion)

      // æ¯æ¬¡å“åº”å®Œæˆæ—¶å¯ä»¥åšä¸€äº›å¤„ç†ï¼Œä¾‹å¦‚è®¡ç®—å½“å‰æ¶ˆè€—çš„ Token æ•°é‡
      const usageInfo = new GPTTokens({
        model: 'gpt-3.5-turbo-1106',
        messages: [...messages, { role: 'assistant', content: completion }],
      })
      console.info('Used tokens: ', usageInfo.usedTokens)
      console.info('Used USD: ', usageInfo.usedUSD)
    },
  })

  return new Response(stream)
}
```

## API

`OpenAIStream` æœ‰ä»¥ä¸‹å±æ€§ï¼š

### å‚æ•°

#### `response`

- Type: `'Response' | 'StreamChatCompletionResponse'`

æ”¯æŒ `OpenAI` chat completions ä»¥åŠ `fetch` è¿”å›çš„ Response å¯¹è±¡ã€‚

#### `callbacks`(optional)

- Type: `'StreamCallbacksOptions'`

æ”¯æŒä¼ å…¥å›è°ƒæ¥è¿›è¡Œæ›´å¤šçš„æ“ä½œå¤„ç†ã€‚

### å‚æ•°ç±»å‹

#### `StreamCallbacksOptions`

{/* This is an object that contains the following properties: */}
è¯¥å¯¹è±¡å…·æœ‰ä»¥ä¸‹å±æ€§ï¼š

<OptionTable
  language="zh-CN"
  options={[
    ['onStart', '() => Promise<void> | void', 'æµå¼å“åº”å¼€å§‹æ—¶è°ƒç”¨'],
    [
      'onCompletion',
      '(completion: string) => Promise<void> | void',
      'æµå¼å“åº”ç»“æŸåè°ƒç”¨ï¼Œå¹¶è¿”å›å½“å‰å“åº”çš„æ–‡æœ¬å†…å®¹',
    ],
  ]}
/>
